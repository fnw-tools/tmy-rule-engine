表达式计算 { .text-center }
---------

&nbsp;

### 任务调度器

```
 +--------------------+            +------------------+
 | +---------+        |         +--|    TMY plugins   |
 | | globals |  +-----+-----+   |  +------------------+
 | +---------+  |           |   |
 | +---------+  |   task    |   |  +------------------+
 | | locals  |  | scheduler +---+--|history ask-answer|
 | +---------+  |           |   |  +------------------+
 |              +-----+-----+   |
 |                    |         |  +------------------+
 |  Rule Engine VM    |         +--|  chatGPT server  |
 +--------------------+            +------------------+
```

规则引擎中驻留一个任务调度器（task scheduler），当用户在聊天室输入一句提问，某个预设的触发词被触发，为完成对该提问的一次响应，一个 WAITING_COMPLETION 任务随即被 task scheduler 创建，并以异步方式由 task scheduler 监控执行。

WAITING_COMPLETION 任务视情况，可以分解成一个或若干个子任务去执行，若有填密语插件（TMY plugins）被调用时，子任务一般至少 2 个。举例来说，一个典型用法是，系统先调用 GOOGLE_PRE_SEARCH 插件联网查询用户的提问，获得若干 google 搜索结果后，进入下个子任务，把搜索结果作为子任务的输入，比方，提交到 chatGPT 与之完成一次问答。

任务调度器工作在 Rule Engine VM 的输入输出界面上，任务调度器向 VM 输入一句脚本表达式（expression），解释器执行后返回结果值。在一个 WAITING_COMPLETION 任务执行过程中，任务调度器会向 VM 请求许多次表达式计算。同时，任务调度器还依据需要，调用各项插件完成特定功能，与大语言模型（LLM）实现问答交互，其间还可能提取历史问答，以便为与 LLM 的交互提供上下文信息。

&nbsp;

### 与 chatGPT 交互时的脚本计算过程

根据 chatGPT 接口规格，完成一次调用需事先确定如下参数：

1. model，模型名称
2. temperature，温度
3. max_tokens，一次问答的最大 tokens 数
4. messages，上下文信息

其中，model 从 `room_cfg.MODEL` 获取，若未定义自动取 "gpt-3.5-turbo" 值。temperature 与 max_tokens 可借助表达式以动态算得，也可在 `room_cfg.temperature` 与 `room_cfg.max_tokens` 固定配置。

其中 messages 缺省取自历史问答记录，不过，room 定义中若干配置项可以影响 messages 如何组织。包括：

- `room_cfg.context_size` 指示取最近几条历史问答作为本次问答的下文，缺省取 5 条（即 5 问 5答）
- `room_cfg.reset_context` 指示是否在本次问答前清除历史记录，缺省为 False

同时，`room_cfg.prompts` 中各触发词的 prompt 定义中，也能通过指定 context_size 与 reset_context 值来影响 messages 上下文如何组织。触发词 prompt 定义指定的 context_size 与 reset_context 将覆盖 `room_cfg.context_size` 与 `room_cfg.reset_context` 配置项。

触发词的 prompt 定义可以指定 `context_size, reset_context, temperature, max_tokens` 四个变量，这四者若定义了，均覆盖 `room_cfg` 下同名配置的定义。另外，这 4 个变量既可指定常量值，也可以指定一个需动态计算的表达式。比如：

```
"prompts": {
  "翻译":{ "prefix": [
    {"ask":"我希望你同时扮演中文翻译、拼写纠正和改进者角色。我会以任何语言与你交谈，你会检测语言，翻译它，并用更为优美、高雅的高级中文词汇和句子来回答我的文本，保持意义相同，但使它们更具文学性，请只回复更正和改进，不要写解释。","answer":"好的"}, 
    {"ask":"istanbulu cok seviyom burada olmak cok guzel","answer":"我非常喜欢伊斯坦布尔，在这里很愉快。"}],
    
    "ask":"",
    "max_tokens":"{allowed_tokens!r} + 1000", "temperature":1.2,
    "context_size":0, "reset_context":true
  }
}
```

这里，max_tokens 是一句表达式，任务调度器会自动识别它需不需要计算，`"{allowed_tokens!r} + 1000"` 含义是取 allowed_tokens 变量的值，再加上 1000。

触发词的 prompt 定义中，可以用 `"prefix"` 项指定聊天的上下文，上下文是一个列表，列表各项包含 ask 与 answer 字串值。与 LLM 聊天的 prompt 定制，主体工作就是确定这里的上下文该如何表达。同样，这里上下文列表中各项定义，也允许使用变量引用与字串引用，关于这两种引用的区别，请参考后文解释。

&nbsp;

### 变量引用与字串引用

上面举列的 `"{allowed_tokens!r} + 1000"` 会被任务调度器视作一个表达式 expression，是因为该字串存在 `{var_name!r}` 变量引用的表达方式，凡有变量引用都被看成表达式，才可以被解释器动态计算。

除了 `{var_name!r}` 变量引用，我们的虚拟机还支持 `{var_name}` 的字串引用的方式，也就是，将 var_name 变量看成字串实施替换。比如：

```
"prompts": {
  "特产":{"ask":"请问 {where} 景点有什么特产？", "context_size":5, "temperature":0}
}    
```

这里，where 变量的字串值（如果变量不是字串类型，会先转化成字串）将被替换到 `"ask"` 的值项中。

请注意，`{var_name}` 替换与 `{var_name!r}` 替换后再计算两者的差别，须小心，不要混淆。前者只替换，并不请求解释器实施计算，后者则用 `repr(var_name)` 值先替换，然后再调用解释器完成计算。比如 `"{var_a} + {var_b}"` 并不被任务调度器视作表达式，因为不存在变量引用，而 `"{var_a!r} + '{var_b}'"` 视为表达式，会自动计算。总之，字串中至少有一次变量引用，任务调度器才会把它看成表达式。

