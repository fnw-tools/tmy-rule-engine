用规则引擎定义样本 { .text-center }
---------------

&nbsp;

### 启发式聊天

前面我们介绍的 prompt 构造方法，都属于零样本提示，接下来我们介绍带样本的 prompt 提示如何定义。

由于 LLM 模型的应用特点，我们与 AI 聊天时，如果前置插入若干问答范例，AI 会有更优表现。现在，我们为 “旅游服务” 再增加一个 `"翻译"` 触发词，将若干对话样本前置到一次聊天的上下文中。

<pre><code class="tmy-room">
{
  "room_ver": 1,
  "room_name": "旅游服务",
  "room_desc": "本聊天室提供旅行服务，可以让机器人介绍景点、介绍当地特产、翻译外文等。",
  
  "system_role": "你是一个友善的导游",
  "context_size": 1,
  "temperature": 0.7,
  "max_tokens": 600,
  
  "globals": {"where":"北京故宫"},
  "magic_rules": {
    "介绍":[["景点名","replace","{where}"], "*"],
    "特产":["*"],
    "翻译":["*"]
  },
  "prompts": {
    "介绍":{ "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。", "context_size":3, "temperature":0 },
    "特产":{ "ask":"请问 {where} 景点有什么特产？", "context_size":5, "temperature":0},
    "翻译":{ "prefix": [
      {"ask":"我希望你同时扮演中文翻译、拼写纠正和改进者角色。我会以任何语言与你交谈，你会检测语言，翻译它，并用更为优美、高雅的高级中文词汇和句子来回答我的文本，保持意义相同，但使它们更具文学性，请只回复更正和改进，不要写解释。","answer":"好的"}, 
      {"ask":"istanbulu cok seviyom burada olmak cok guzel","answer":"我非常喜欢伊斯坦布尔，在这里很愉快。"}],
      "ask":"",
      "max_tokens":1000, "temperature":1.2,
      "context_size":0, "reset_context":true
    }
  },
  "hint_magics": ["介绍","特产","翻译"],
  "state_desc": "({where})"
}
</code></pre>

这里，prompts 的 `"翻译"` 项中定义的 prefix 是前置样本，我们用 "ask" 与 "answer" 范例指示 AI 尽量按我们的意图进行应答 。

&nbsp;

### 触发中临时调整环境变量

上面 prompts 定义中，我们还指定 temperature 为 `1.2`，这将让 AI 回答更有创意，再指定 reset_context 为 true，表示此前的历史对话将被忽略，设置 context_size 为 0，指示紧接本次问答之后的聊天，记忆深度为 0，即，不上传历史记录。

比方用户输入："翻译 ヒグマとの危険な遭遇を避けてもらおうと、北海道警函館方面本部がクマの出没情報をまとめた管内の地図を作り、ウェブサイトで公表している。"，AI 将响应："为了避免与棕熊发生危险的接触，北海道警察函馆方面本部已制作了棕熊出没信息地图并在网上公布 "。说明，本处举例只为了方便讲解，其实更适合旅游的翻译服务，可能是用户拍照上传图片，由 AI 从中识别外国文字，然后优雅的翻译成自己熟悉的语言。

我们为 `"特产"` 触发词指定的 context_size 为 5，便于在 AI 答复景点有什么特产后，用户可以接着按常规聊天方式，比方进一步询问各类特产详情。而指定 `"翻译"` 触发词的 context_size 为 0，是不希望在翻译之后继续聊天。这里在触发词的 prompts 中定义的 context_size 不是全局定义，具有临场生效生效的特点。所谓临场，是指相应触发词被触发之后紧随着的聊天按这个 context_size 取值确定上下文深度，而隔了好久（比方超过 10 分钟）才续上的聊天，系统将自动重置为全局 context_size 定义，如，本例中全局 context_size 取值 1。
