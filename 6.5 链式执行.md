链式执行 { .text-center }
-------

&nbsp;

### 执行体

上一节以 chatGPT 聊天时的脚本计算为例，介绍了 TMY 规则引擎的 VM 如何计算各项 expression 表达式。

调用 LLM API 完成一次聊天问答，被任务调度器（task scheduler）看成一个 “执行体” 完成一项任务。除了 LLM 问答机可以充当执行体，规则引擎的各类插件，也充当执行体，一个插件充当一个执行体。事实上，任务调度器监控一个 LLM 问答机的执行过程，也把它看作一种插件去处理的。规则引擎中插件有多个，LLM 问答机也可以有多个。

执行体的输入固定为 utf8 格式的字串，如果类型不匹配，系统会自动尝试转换它，比如将 bytes 类型 decode 成 utf8 字串。LLM 问答机的输入通常是用户提交的问题，插件的输入可是用户提交的问题，也可以是某个预指定的变量。执行体的输出则可以是任意受支持的数据类型，如：`bool, int, float, string, tuple, list, dict, set` 等。

所有执行体都使用 `STEP_ERROR` 与 `STEP_RESULT` 两个局部变量，执行中但凡出错，都应将一句出错描述（字串类型）赋给 `STEP_ERROR`，该变量缺省取空字串值，表示尚未出错。而执行体的运行结果将自动赋给 `STEP_RESULT` 变量。 

&nbsp;

### 链式执行

多个执行体可以串接起来运行，前面执行体的运行结果（存为 `STEP_RESULT` 变量）通常会影响后面执行体如何运行，即前面的输出（或输出的一部分）可能用作后面执行体的输入，前面的输出，还可能作为 VM 环境中的全局变量，通过变量引用影响后续执行体的表达式计算。另外，任一执行如果运算出错，都通过设置 `STEP_ERROR` 指明出错原因，同时，该值非空会将导致后续任务自动取消。

在聊天室定义中，我们可以在 prompts 下定义某个触发词将触发怎样的一个任务链 TASK_CHAIN，任务链是单执行体时，用 `{magic:task}` 格式在 `room_cfg.prompts` 指定相应执行体即可，如下例。

``` json
{
  "room_ver": 1,
  "room_name": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "context_size": 1,
  "temperature": 0.7,
  "max_tokens": 600,
  
  "magic_rules": {
    "介绍":[["景点名","replace","{where}"], "*"]
  },
  "prompts": {
    "介绍":{ "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。",
      "context_size":3, "temperature":0
    }
  },
  "hint_magics": ["介绍"]
}
```

定义多执行体，如下例。

``` json
{
  "room_ver": 1,
  "room_name": "旅游服务",
  
  "system_role": "你是一个友善的导游",
  "context_size": 1,
  "temperature": 0.7,
  "max_tokens": 600,
  
  "magic_rules": {
    "介绍":[["景点名","replace","{where}"], "*"]
  },
  "prompts": {
    "介绍":[ {
      "ask":"我提供一个景点名称，你将介绍该景点的特色、人文背景、历史典故，简短些。请介绍景点：{where} 。",
      "context_size":3, "temperature":0
    }, {
      "uri":"ADJUST",
      "save":"last_answer"
    }]
  },
  "hint_magics": ["介绍"]
}
```

本处 `{magic:task}` 的 task 是执行体列表（列表共有 2 项，而非单个执行体）。在任何执行体的任务定义中，如果存在 ask 字段，表明这是 LLM 问答机，如果存在 uri 字段，表明这是扩展插件执行体，uri 字段用于标识插件 ID。

规则引擎对其下所有执行体的输入输出规格作了统一规定，详情在下一章介绍。
